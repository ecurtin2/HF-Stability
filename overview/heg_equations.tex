\documentclass{revtex4}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{braket}
\usepackage{mathtools}
\usepackage{textcomp}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother

\begin{document}
\title{Notes on Hartree-Fock Stability of HEG}
\author{Evan Curtin}
\maketitle


\section{Homogeneous Electron Gas}

The Fermi level, $k_f$, is (p. 30 of \cite{Guiliani2005})

\begin{equation}
k_f
=\begin{cases} 
      (3\pi^2n)^{\frac{1}{3}} = \left(\frac{9\pi}{4}\right)^{\frac{1}{3}}\frac{1}{r_sa_0} & 3D \\ \\
      (2\pi n)^{\frac{1}{2}} = \frac{\sqrt{2}}{r_sa_0}  & 2D \\
      \\
      \frac{\pi}{2}n = \frac{\pi}{4 r_s a_0}   & 1D 
   \end{cases}
   .
\end{equation}

The two electron integral is given by (eq. 12 of \cite{Delyon2008} and p. 16 of \cite{Guiliani2005})

\begin{subequations}
\begin{align}
\braket{\vec{k}, \vec{k}'|\vec{k}'',\vec{k}'''}\stackrel{\text{2D, 3D}}{=}&
	\begin{cases} 
	\frac{\pi}{\Omega}\frac{2^{D-1}}{|\vec{k}-\vec{k}''|^{D-1}} 
	& \vec{k}''' = \vec{k}+\vec{k}'-\vec{k}'' \textbf{ and } |\vec{k}-\vec{k}''| \neq 0 \\
	0 
	& \text{else}
	\end{cases}
\\ \nonumber \\
\braket{k, k'|k'',k'''}\stackrel{\text{1D}}{=}&
	\begin{cases} 
	e^{|k-k''|^2a^2}\text{Ei}(-|k-k''|^2a^2)\text{ ;}
	& k''' = k+k'-k'' \textbf{ and } |k-k''| \neq 0 \\
	0\text{ ;} 
	& \text{else}
	\end{cases}
\end{align}
\end{subequations}
where $\Omega$ is the direct lattice volume and D is the dimensionality of the system. Ei(x) denotes the exponential integral function. The orbital energies are given by 

\begin{equation}
\epsilon_{\vec{k},\sigma}=
\begin{cases}
	\frac{\hbar^2\vec{k}^2}{2m}-\left(\frac{L}{2\pi}\right)^D\int\limits_{|\vec{k}'|<\vec{k}_f}^{}\braket{\vec{k}, \vec{k}' |\vec{k}', \vec{k}}d\vec{k}'
	&\text{continuous (eq. 23 of \cite{Yamada2015})} \\
	\frac{\hbar^2\vec{k}^2}{2m} - \sum\limits_{\vec{k}}^{|\vec{k}|< k_f}n_{\vec{k}\sigma}\braket{\vec{k}, \vec{k}' |\vec{k}', \vec{k}}
	&\text{discrete (p. 80 of \cite{Guiliani2005})}
\end{cases}
\end{equation}
Where $n_{\vec{k}\sigma}$ is the occupation number of the state with momentum $\vec{k}$ and spin $\sigma$. Here we have used the relationship to relate the discrete and continuous quantities, (p. 15 of \cite{Guiliani2005})

\begin{equation}
	\sum\limits_{\vec{k}}^{}{(...)}\xrightarrow{\text{$dk \ll L$}}\left(\frac{L}{2\pi}\right)^D\int (...)d\vec{k}
\end{equation}

The analytic form of the exchange energy is known in the continuous case. Let $y = \frac{k}{k_{F\sigma}}$. Equations \ref{eq:hfexch} through \ref{eq:fnd} are from p. 81-82 of \cite{Guiliani2005}. In 2 or 3 dimensions the exchange energy is, 

\begin{equation}\label{eq:hfexch}
\epsilon_{k\sigma}^{(x)} = -\frac{2e^2k_{F\sigma}}{\pi}f_{ND}\left(\frac{k}{k_{F\sigma}}\right),
\end{equation}
where in 3D, the function $f_{3D}$ is given by
\begin{equation}
f_{3D}\left(y\right) = \frac{1}{2} + \frac{1-y^2}{4y} ln \left|\frac{1+y}{1-y} \right|,
\end{equation}
and in 2D, it is
\begin{equation}\label{eq:fnd}
f_{2D}\left(y\right) = 
\begin{cases} 
    \mathbf{E}\left(y\right), &  y \leq 1, \\
    y 
    \left[ 
        \mathbf{E} 
        \left(
            \frac{1}{y} 
        \right)
        -
        \left(
            1 - \frac{1}{y^2}
        \right)
        \mathbf{K}
        \left(
            \frac{1}{y}
        \right)
       \right]  ,& y \geq 1. 
\end{cases}
\end{equation}
The functions $\mathbf{K}(y)$ and $ \mathbf{E}(y) $ are complete elliptic integrals of the first and second kind, respectively. These are implemented in SciPy as \emph{scipy.special.ellipk} and \emph{scipy.special.ellipe}. After a significant struggle, I have found that the author of the textbook\cite{Guiliani2005} and scipy/wolfram use a different definition of the complete elliptic integral. I was able to reproduce the graphs on pages 82 and 83 of \cite{Guiliani2005} properly with $\mathbf{K}(x) \rightarrow \mathbf{K}(x^2)$ and $\mathbf{E}(x) \rightarrow \mathbf{E}(x^2)$.

\section{Hartree-Fock Stability}
The HF stability conditions (to my knowledge) were presented by Thouless \cite{Thouless1972} ($1^{st}$ Ed. 1960). More general conditions were presented by Adams\cite{Adams1962}. The stability condition is that the eigenvalues ($\lambda$) given by (p. 41 of \cite{Thouless1972}) 

\begin{equation}
(\epsilon_a-\epsilon_i)C_{ai} + \sum\limits_{\text{j}}^{occ}\sum\limits_{\text{b}}^{vir}
	(\braket{aj|ib}-\braket{aj|bi})C_{bj}
	+(\braket{ab|ij}-\braket{ab|ji})C_{bj}^*
	=\lambda C_{ai}
\end{equation}

\begin{equation}
(\epsilon_a-\epsilon_i)C_{ai}^* + \sum\limits_{\text{j}}^{occ}\sum\limits_{\text{b}}^{vir}
	(\braket{ij|ab}-\braket{ij|ba})C_{bj}
	+(\braket{ib|aj}-\braket{ib|ja})C_{bj}^*
	=\lambda C_{ai}^*,
\end{equation}
are nonnegative. This is equivalent to the RPA oscillation frequencies being all real (p. 115 of \cite{Thouless1972}). The RPA is a linearized approximation to Time-Dependent Hartree-Fock theory. These can be written\cite{Dunning1967}\cite{Seeger1977} in the following form:
\begin{equation}\label{eq:1,3H}
{}^{1,3}\bf{H'}=
\begin{bmatrix}
{}^{1,3}\bf{A'} & {}^{1,3}\bf{B'} \\
\left({}^{1,3}\bf{B'}\right)^* & \left({}^{1,3}\bf{A'}\right)^* \\
\end{bmatrix}
\end{equation}
Where the $1,3$ denote singlet and triplet states, respectively. $\bf{A}$, $\bf{B}$ have dimension $N_{occ}\times N_{vir}$ and are defined as follows:
\begin{subequations}
	\begin{align}
	{}^{1}{A'}_{i\rightarrow a, j\rightarrow b} &= (\epsilon_a-\epsilon_i)\delta_{ij}\delta_{ab} + 2\braket{aj|ib}-\braket{aj|bi}\\
	{}^{3}{A'}_{i\rightarrow a, j\rightarrow b} &= (\epsilon_a-\epsilon_i)\delta_{ij}\delta_{ab} - \braket{aj|bi}\\
	{}^{1}{B'}_{i\rightarrow a, j\rightarrow b} &= 2\braket{ab|ij}-\braket{ab|ji}\\
	{}^{3}{B'}_{i\rightarrow a, j\rightarrow b} &= -\braket{ab|ji}
	\end{align}
\end{subequations}
The matrix given in Equation \ref{eq:1,3H} represents the case of complex RHF stability in the space of complex RHF space (${}^{1}\mathbf{H}$ - internal instability) and in the space of complex UHF space (${}^{3}\mathbf{H}$ - triplet instability). Seeger and Pople \cite{Seeger1977} give both more general formulae, and simplifications in special cases. Figure \ref{fig:stability_table} is a reproduction of the stability conditions they developed, and more details can be found in the paper. 
\begin{figure}[h]
   \includegraphics[width=1.0\linewidth]{figures/seeger_stability.pdf}
  	\caption {Hartree-Fock Stability conditions reproduced from Seeger \& Pople \cite{Seeger1977}}
  	\label{fig:stability_table}
\end{figure} 

\section{Davidson's Algorithm}
\subsection{Theory}
Oftentimes we're interested only in the lowest or highest few eigenvalues of a large, symmetric matrix. Matrix eigenvalue problem operation counts scale as \url{~}$O(N^3)$ for an $N \times N$ matrix, while the memory requirement scales quadratically. Iterative subspace methods based off the Rayleigh-Ritz method are popular ways of dealing with this issue. The most famous are the Lanczos (hermitian) and Arnoldi (non-hermitian) algorithms, which build as their subspace a Krylov space. A more involved algorithm was proposed by Davidson\cite{Davidson1975} and involves building a subspace with correction vectors to be described momentarily. But first, a few definitions are introduced to define the notation to be used.

We are interested in the lowest (or highest) $k$ ($0 < k \leq N$) eigenvalue(s) of the $N \times N$ hermitian matrix, A,
\begin{equation}
\bf{Ax}=\lambda\bf{x}
\end{equation}
We begin by guessing $M$ ($M \geq k$) vectors, $\bf{v}$ which approximately span the space of the actual eigenvectors. Let $\bf{V}$ be the $N\times M$ matrix whose columns are the approximate eigenvectors, 
\begin{equation}
\bf{V}=[\bf{v_1,v_2,...,v_M}]	
\end{equation}
where care must be taken to ensure columns of $\bf{V}$ form an orthogonal set. We then transform our matrix into the subspace as follows, 
\begin{equation}
\bf{\tilde{A}} = \bf{V}^\dag\bf{AV}
\end{equation}
where the \url{~} will be used to denote entities in the subspace. $\bf{\tilde{A}}$ is an $M \times M$ matrix where $M \ll N$, and therefore we can use standard diagonalization routines to calculate the eigenvalues and eigenvectors in the subspace, 
\begin{equation}
\bf{\tilde{A}\tilde{x}}=\tilde{\lambda}\bf{\tilde{x}}
\end{equation}
The subspace eigenpair $(\tilde{\lambda}_i,\mathbf{\tilde{x}}_i)$ is then used to create the \emph{Ritz pair}, $({\lambda_i^R},\mathbf{x}_i^R)$. The ritz pair is the approximation to the exact eigenpair of the matrix, and is determined by
\begin{subequations}
	\begin{align}
	 \mathbf{x_i} &\approx \mathbf{x}_i^R = \mathbf{V\tilde{x}}_i\\
	 \lambda_i &\approx \lambda_i^R = \tilde{\lambda}_i
	\end{align}
\end{subequations}
At any time, the quality of the approximation can be determined by calculating the norm of the \emph{residue},
\begin{equation}
\mathbf{r}_i=\left(\mathbf{A}-\lambda_i\mathbf{I}\right)\mathbf{x}_i^R
\end{equation}
when $||\mathbf{r}_i||$ is smaller than a given tolerance for the desired k eigenpairs, the algorithm is finished and the current Ritz pairs are taken to be the eigenpairs. If this condition is not met, the subspace needs to be expanded. This is done by computing correction vectors, $\mathbf{\delta}_i$,
\begin{equation}
\mathbf{\delta}_i = c_i\mathbf{r}_i
\end{equation}
for $i =0...l$ where $l$ is the number of desired ritz pairs with $||\mathbf{r}_i||$ greater than the given tolerance. Corrections are only calculated for these Ritz pairs. The coefficient, $c_i$ is a preconditioner. The original choice of $c_i$ introduced by Davidson\cite{Davidson1975} was diagonal preconditioning, 
\begin{equation}
c_i = \frac{1}{\lambda_i\mathbf{I}-\mathbf{D}}
\end{equation}
where $\mathbf{D}$ is the $N\times N$ diagonal matrix consisting of the diagonal elements of $\mathbf{A}$, and $\mathbf{I}$ is the identity matrix of the same size. It may help convergence to use a modified version of this approach, 
\begin{equation}
c_i = \frac{1}{\rho_i\mathbf{I}-\mathbf{D}}
\end{equation}
where $\rho_i$ is the \emph{rayleigh quotient}, defined by
\begin{equation}
\rho_i = \frac{\mathbf{x}_i^{R\dag}\mathbf{A}\mathbf{x}_i^{R}}{||\mathbf{x}_i^{R}||}
\end{equation}
The rayleigh quotient from a physicist's perspective is $\rho_i = \braket{\mathbf{x}_i^{R}|\mathbf{A}|\mathbf{x}_i^{R}}$, which looks like the expectation value of $\mathbf{A}$ in the state $\mathbf{x}_i^{R}$. As $\mathbf{x}_i^{R}$ approaches the actual eigenstate of the system, the rayleigh quotient approaches the eigenvalue.
\\\\
The correction vector is then added to $\mathbf{V}$ and the process is repeated. The correction vector must be normalized and orthogonalized to the columns of $\mathbf{V}$. The subspace size is therefore increased by $l$. 
\begin{subequations}
\begin{align}
\mathbf{V} &= [\mathbf{v_1,v_2,...,v_M}\mathbf{,\delta}_1\mathbf{,\delta}_2,...\mathbf{,\delta}_l] \\
\mathbf{V} &= orthonormalized(\mathbf{V})\\
M &= M + l
\end{align}
\end{subequations}

\subsection{Implementation}
\begin{algorithm}[H]
\caption{Davidson's Algorithm}\label{davidson}
\begin{algorithmic}[1]
\State create \bf{V}
\For {$i = 0, max\text{ }iterations$}
\State $\bf{\tilde{A}} = \bf{V}^\dag\bf{AV}$
\State $\tilde{\lambda},\mathbf{\tilde{x}} = eigensystem(\bf{\tilde{A}})$
\State sort $\tilde{\lambda},\mathbf{\tilde{x}}$
\If {$i > \textit{stringlen}$} \Return false
\EndIf
\State $j \gets \textit{patlen}$
\If {$\textit{string}(i) = \textit{path}(j)$}
\State $j \gets j-1$.
\State $i \gets i-1$.
\State \textbf{goto} \emph{loop}.
\State \textbf{close};
\EndIf
\State $i \gets i+\max(\textit{delta}_1(\textit{string}(i)),\textit{delta}_2(j))$.
\State \textbf{goto} \emph{top}.
\EndFor

\end{algorithmic}
\end{algorithm}


\section{Code Layout}
\begin{figure}[H]
   \includegraphics[width=1.0\linewidth]{figures/hf_stability_diagram.eps}
   \caption {Layout of code implementation. Red boxes are python, blue are C++ and purple dotted lines require cython. Green are likely to be removed for speed}
   \label{fig:code_diagram}
\end{figure} 

\section{References}
\bibliography{heg_references}
\end{document}
